# nginx.conf  --  docker-openresty
#
# This file is installed to:
#   `/usr/local/openresty/nginx/conf/nginx.conf`
# and is the file loaded by nginx at startup,
# unless the user specifies otherwise.
#
# It tracks the upstream OpenResty's `nginx.conf`, but removes the `server`
# section and adds this directive:
#     `include /etc/nginx/conf.d/*.conf;`
#
# The `docker-openresty` file `nginx.vh.default.conf` is copied to
# `/etc/nginx/conf.d/default.conf`.  It contains the `server section
# of the upstream `nginx.conf`.
#
# See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files
#

#user  nobody;
#worker_processes 1;

# Enables the use of JIT for regular expressions to speed-up their processing.
pcre_jit on;



#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# 开启debug级别日志，否则ngx.log不能输出debug级别日志
# https://stackoverflow.com/questions/55975325/nothing-is-written-to-nginx-access-log-error-log-how-to-troubleshoot
error_log  logs/error.log  debug;

#pid        logs/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    # Enables or disables the use of underscores in client request header fields.
    # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive.
    # underscores_in_headers off;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

        # Log in JSON Format
        # log_format nginxlog_json escape=json '{ "timestamp": "$time_iso8601", '
        # '"remote_addr": "$remote_addr", '
        #  '"body_bytes_sent": $body_bytes_sent, '
        #  '"request_time": $request_time, '
        #  '"response_status": $status, '
        #  '"request": "$request", '
        #  '"request_method": "$request_method", '
        #  '"host": "$host",'
        #  '"upstream_addr": "$upstream_addr",'
        #  '"http_x_forwarded_for": "$http_x_forwarded_for",'
        #  '"http_referrer": "$http_referer", '
        #  '"http_user_agent": "$http_user_agent", '
        #  '"http_version": "$server_protocol", '
        #  '"nginx_access": true }';
        # access_log /dev/stdout nginxlog_json;

    # See Move default writable paths to a dedicated directory (#119)
    # https://github.com/openresty/docker-openresty/issues/119
    client_body_temp_path /var/run/openresty/nginx-client-body;
    proxy_temp_path       /var/run/openresty/nginx-proxy;
    fastcgi_temp_path     /var/run/openresty/nginx-fastcgi;
    uwsgi_temp_path       /var/run/openresty/nginx-uwsgi;
    scgi_temp_path        /var/run/openresty/nginx-scgi;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    # 反向代理配置
    # proxy_buffering: 控制是否启用代理响应缓冲
    # on: 启用缓冲（默认值）
    #     当启用时，nginx会先将后端服务器的完整响应读取到内存缓冲区中，然后再发送给客户端
    #     优点：
    #     - 减少与后端服务器的连接时间，后端可以更快地释放连接
    #     - 允许nginx在发送响应给客户端之前进行优化处理（如压缩、缓存等）
    #     - 对于慢速客户端，可以避免长时间占用后端连接
    #     - 提高后端服务器的吞吐量，因为连接可以更快地复用
    #     缺点：
    #     - 增加内存使用，特别是对于大文件响应
    #     - 增加响应延迟，因为需要等待完整响应后才能开始发送给客户端
    #     - 对于流式响应（如实时数据、大文件下载）可能不适用
    # off: 禁用缓冲
    #      当禁用时，nginx会立即将后端服务器的响应转发给客户端（流式传输）
    #      适用于：
    #      - 需要实时传输的场景（如SSE、WebSocket升级后的数据传输）
    #      - 大文件下载，避免内存占用过大
    #      - 需要低延迟的场景
    # 注意：proxy_buffering 与 proxy_cache 配合使用时，即使 buffering=off，
    #       nginx仍然需要缓冲响应以便写入缓存，但会尽可能快地同时发送给客户端
    proxy_buffering on;
    # proxy_buffer_size: 设置用于读取后端服务器响应头部的缓冲区大小
    # 8k: 缓冲区大小为8KB（8192字节）
    #     这是第一个缓冲区，专门用于读取响应头（HTTP headers）
    #     响应头通常包含：Content-Type、Content-Length、Cache-Control、Set-Cookie等
    # 为什么需要单独的头部缓冲区？
    # - nginx需要先读取完整的响应头才能决定如何处理响应（如是否缓存、如何转发等）
    # - 响应头通常较小（几百字节到几KB），但必须完整读取
    # - 如果响应头超过此大小，nginx会返回502错误（upstream sent too big header）
    # 常见问题：
    # - 如果后端返回的响应头很大（如包含大量Set-Cookie、自定义头部等），
    #   可能需要增大此值，例如：proxy_buffer_size 16k; 或 proxy_buffer_size 32k;
    # - 如果设置过小，可能导致502错误："upstream sent too big header while reading response header"
    # - 如果设置过大，会浪费内存（因为每个请求都会分配这个大小的缓冲区）
    # 与其他缓冲区指令的关系：
    # - proxy_buffer_size: 第一个缓冲区，用于响应头
    # - proxy_buffers: 后续缓冲区，用于响应体（见下一行）
    # - proxy_busy_buffers_size: 正在发送给客户端的缓冲区大小限制（见第112行）
    # 默认值：通常为 proxy_buffer_size 4k|8k;（取决于平台）
    # 建议值：
    # - 一般场景：8k（默认值通常足够）
    # - 响应头较大：16k 或 32k
    # - 响应头非常大：64k（不常见，需要检查后端配置）
    proxy_buffer_size 8k;
    # proxy_buffers: 设置用于读取后端服务器响应体的缓冲区数量和大小
    # 32 8k: 表示分配32个缓冲区，每个缓冲区大小为8KB
    #        总缓冲区大小 = 32 × 8KB = 256KB
    #        这些缓冲区用于读取响应体（response body），不包括响应头
    # 工作原理：
    # - 当nginx从后端读取响应时，会使用这些缓冲区来存储响应体数据
    # - 如果响应体小于256KB，所有数据会存储在内存中
    # - 如果响应体超过256KB，nginx会将超出部分写入临时文件（由proxy_temp_path指定）
    # - 缓冲区采用链表结构，按需分配，用完后会释放
    # 为什么需要多个缓冲区？
    # - 后端可能以块（chunk）的形式发送数据，多个缓冲区可以并行接收
    # - 提高读取效率，减少等待时间
    # - 允许nginx在处理一个缓冲区数据的同时，继续从后端读取数据到其他缓冲区
    # 缓冲区大小选择：
    # - 8k: 每个缓冲区8KB，这是常见的选择
    #       8KB通常是系统页大小的倍数（Linux通常为4KB），有利于内存对齐和性能
    #       对于大多数Web响应，8KB是一个平衡点
    # - 也可以使用其他大小，如4k、16k等，但8k是最常用的
    # 缓冲区数量选择：
    # - 32: 表示32个缓冲区
    #       默认值通常是8个缓冲区，32个意味着更大的总缓冲区空间
    # - 更多缓冲区的好处：
    #   * 可以缓存更大的响应体在内存中，减少磁盘I/O
    #   * 对于中等大小的响应（如JSON API响应、HTML页面），可以完全在内存中处理
    # - 更多缓冲区的缺点：
    #   * 增加内存使用（每个请求最多占用 32×8k=256KB）
    #   * 对于大量并发请求，内存压力会增大
    # 内存占用计算：
    # - 每个请求最多占用：proxy_buffer_size + proxy_buffers = 8k + (32×8k) = 264KB
    # - 100个并发请求：约26.4MB内存
    # - 1000个并发请求：约264MB内存
    # 何时需要调整？
    # - 响应体经常超过256KB：增加缓冲区数量或大小，例如：proxy_buffers 64 8k; 或 proxy_buffers 32 16k;
    # - 内存紧张：减少缓冲区数量，例如：proxy_buffers 16 8k; 或 proxy_buffers 8 8k;
    # - 响应体很小（如API响应）：可以减少缓冲区数量以节省内存
    # - 响应体很大（如文件下载）：可以增加缓冲区数量，但更好的做法是使用 proxy_buffering off;
    # 与proxy_buffer_size的关系：
    # - proxy_buffer_size: 第一个缓冲区，用于响应头（8k）
    # - proxy_buffers: 后续缓冲区，用于响应体（32个，每个8k）
    # - 两者是分开的，响应头不会占用proxy_buffers的空间
    # 默认值：通常为 proxy_buffers 8 4k|8k;（取决于平台，8个缓冲区，每个4KB或8KB）
    # 建议值：
    # - 一般Web应用：32 8k（当前配置，适合大多数场景）
    # - 内存受限环境：8 8k 或 16 8k
    # - 大响应体场景：64 8k 或 32 16k
    # - 超大响应体（文件下载）：考虑使用 proxy_buffering off; 进行流式传输
    proxy_buffers 32 8k;
    # proxy_busy_buffers_size: 设置正在发送给客户端的缓冲区大小限制
    # 16k: 限制正在发送给客户端的缓冲区总大小为16KB
    #      这些缓冲区被称为"busy buffers"（忙碌缓冲区），因为它们正在被使用
    # 工作原理：
    # - 当nginx从后端读取响应并准备发送给客户端时，会使用缓冲区来存储数据
    # - proxy_busy_buffers_size 限制了可以同时用于发送给客户端的缓冲区大小
    # - 剩余的缓冲区可以继续从后端读取数据，实现并行处理
    # - 这样可以避免所有缓冲区都被发送操作占用，导致无法继续从后端读取数据
    # 为什么需要这个限制？
    # - 平衡读取和发送：确保nginx可以同时从后端读取数据和向客户端发送数据
    # - 防止阻塞：如果所有缓冲区都被发送操作占用，就无法继续读取后端响应
    # - 提高吞吐量：通过并行处理，提高整体性能
    # 缓冲区状态分类：
    # - free buffers（空闲缓冲区）：未被使用，可以用于读取后端数据
    # - busy buffers（忙碌缓冲区）：正在发送给客户端，大小受proxy_busy_buffers_size限制
    # - 当busy buffers达到限制时，nginx会等待客户端接收数据，释放缓冲区后再继续读取
    # 大小选择：
    # - 16k: 当前配置，表示最多16KB的缓冲区可以同时用于发送
    #        这个值通常设置为 proxy_buffers 中单个缓冲区大小的1-2倍
    #        当前配置：proxy_buffers 32 8k（每个8k），所以16k = 2个缓冲区
    # - 如果设置过小：
    #   * 可能导致发送速度慢，因为每次只能发送少量数据
    #   * 可能影响整体吞吐量
    # - 如果设置过大：
    #   * 可能占用过多缓冲区用于发送，影响从后端读取数据的能力
    #   * 对于慢速客户端，可能导致大量数据积压在内存中
    # 与proxy_buffers的关系：
    # - proxy_buffers 32 8k: 总共256KB的缓冲区空间
    # - proxy_busy_buffers_size 16k: 其中最多16KB可以同时用于发送
    # - 剩余的240KB可以继续从后端读取数据
    # - 这样可以实现：一边发送16KB给客户端，一边继续从后端读取240KB的数据
    # 实际工作流程示例：
    # 1. nginx开始从后端读取响应，使用proxy_buffers中的缓冲区
    # 2. 当有数据准备好时，开始发送给客户端（最多16KB）
    # 3. 在发送这16KB的同时，继续使用剩余的缓冲区从后端读取数据
    # 4. 当客户端接收了部分数据后，释放一些缓冲区，继续发送更多数据
    # 5. 重复此过程，直到响应完全传输完成
    # 默认值：通常为 proxy_busy_buffers_size 8k|16k;（取决于平台）
    # 建议值：
    # - 一般场景：proxy_buffers中单个缓冲区大小的1-2倍
    #   * 如果 proxy_buffers 32 8k，建议设置为 8k 或 16k
    #   * 如果 proxy_buffers 32 16k，建议设置为 16k 或 32k
    # - 快速客户端（如内网）：可以设置更大，例如 32k 或 64k
    # - 慢速客户端（如移动网络）：可以设置较小，例如 8k
    # - 流式传输场景：如果使用 proxy_buffering off;，此指令无效
    # 注意事项：
    # - proxy_busy_buffers_size 必须小于等于 proxy_buffers 的总大小
    # - 通常设置为 proxy_buffers 中单个缓冲区大小的1-2倍即可
    # - 对于大多数场景，默认值或稍大的值（如16k）已经足够
    proxy_busy_buffers_size 16k;
	# proxy_cache_path: 配置代理缓存路径和相关参数
	# /tmp/cache_temp: 缓存文件存储的磁盘路径，所有缓存文件将存储在此目录下
	# levels=2:2: 设置缓存目录的层级结构，表示使用2级目录，每级目录名长度为2个字符
	#             例如：/tmp/cache_temp/ab/cd/efghijklmnopqrstuvwxyz123456
	#             这样可以避免单个目录下文件过多导致的性能问题
	# keys_zone=cache_zone:128m: 定义缓存键的内存区域
	#             cache_zone: 内存区域的名称，在location中通过 proxy_cache cache_zone 引用
	#             128m: 内存区域大小，128MB，用于存储缓存键和元数据（不是缓存内容本身）
	#             缓存键（cache key）是什么？
	#             缓存键是用来唯一标识一个缓存项的字符串，类似于字典的key或数据库的主键
	#             默认情况下，nginx使用 $scheme$proxy_host$request_uri 作为缓存键
	#             也可以通过 proxy_cache_key 指令自定义，例如：proxy_cache_key $request_uri;
	#             当请求到来时，nginx会根据缓存键查找是否已有缓存：
	#             - 如果找到缓存键对应的缓存文件，且缓存有效，直接返回缓存内容（HIT）
	#             - 如果找不到或缓存已过期，则向后端请求，并将响应缓存起来（MISS）
	#             例如：请求 /test-s-maxage 时，缓存键可能是 "http://backend:80/test-s-maxage"
	#             这个键会存储在内存的 keys_zone 中，用于快速查找对应的缓存文件路径
	# max_size=2g: 缓存的最大磁盘占用空间，超过此大小后，nginx会根据LRU算法删除最久未使用的缓存
	# inactive=30d: 缓存不活跃时间，如果缓存文件在30天内没有被访问，将被删除
	#              即使缓存内容仍然有效，如果长时间不访问也会被清理
	# use_temp_path=off: 是否使用临时路径存储缓存文件
	#                    off表示直接将文件写入最终路径，避免额外的文件移动操作，提高性能
	proxy_cache_path /tmp/cache_temp levels=2:2 keys_zone=cache_zone:128m max_size=2g inactive=30d use_temp_path=off;
	
	upstream backendserver {
		server backend:80;
	}

    server {
    	listen       80;
    	server_name  localhost;
	
		location = / {
            root         /usr/local/openresty/nginx/html;
			try_files /index.html =404;
		}

		location / {
			# proxy_cache: 启用代理缓存功能，指定使用哪个缓存区域
			# cache_zone: 缓存区域的名称，对应 proxy_cache_path 中定义的 keys_zone=cache_zone
			#             当启用此指令后，nginx会对通过 proxy_pass 获取的响应进行缓存
			#             缓存的文件存储在 proxy_cache_path 指定的磁盘路径中
			#             缓存的键和元数据存储在 keys_zone 指定的内存区域中
			#             只有满足缓存条件的响应才会被缓存（如通过 proxy_cache_valid 设置的状态码）
			proxy_cache cache_zone;
    		# proxy_cache_valid: 设置不同HTTP状态码响应的缓存有效期
    		# 200: HTTP状态码，表示成功响应
    		#      只有状态码为200的响应才会被缓存，其他状态码（如404、500等）不会被缓存
    		#      可以设置多个状态码，例如：proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m;
    		# 10s: 缓存有效期，表示缓存10秒后过期
    		#     可以使用的时间单位：s(秒)、m(分钟)、h(小时)、d(天)、w(周)
    		#     例如：10s = 10秒，1h = 1小时，30d = 30天
    		#     过期后的缓存仍然会保留在磁盘上，但nginx会将其视为无效，重新向后端请求
    		#     实际删除时间由 proxy_cache_path 中的 inactive 参数控制
    		# 注意：proxy_cache_valid 设置的是缓存的有效期（何时过期）
    		#       proxy_cache_path 中的 inactive 设置的是不活跃时间（何时删除）
    		#       例如：缓存1年过期，但如果30天内没有访问，也会被删除
    		proxy_cache_valid 200 10s;
    		# proxy_cache_key: 自定义缓存键的生成规则
    		# 默认情况下，nginx使用 $scheme$proxy_host$request_uri 作为缓存键
    		# 例如：http://backend:80/test-s-maxage
    		# $request_uri: nginx变量，包含完整的请求URI（包括查询参数）
    		#              例如：/test-s-maxage 或 /test-s-maxage?param=value
    		#              注意：$request_uri 不包含协议和主机名，只包含路径和查询字符串
    		# 使用 $request_uri 作为缓存键的影响：
    		# - 优点：相同URI的请求会共享缓存，即使请求来自不同的主机或协议
    		# - 缺点：如果后端根据Host头返回不同内容，可能导致缓存混乱
    		#         例如：api.example.com/test 和 www.example.com/test 会共享缓存
    		# 示例：
    		# - 请求 /test-s-maxage，缓存键为 "/test-s-maxage"
    		# - 请求 /test-private?key=value，缓存键为 "/test-private?key=value"
    		# - 两个请求的缓存键不同，会分别缓存
    		# 如果需要包含更多信息，可以使用：
    		# proxy_cache_key "$scheme$request_method$host$request_uri";
    		proxy_cache_key $request_uri;
            # 在开发调试时把缓存状态设置为头部信息，响应给客户端
            # 使用 X- 前缀标识自定义的非标准头部（虽然RFC 6648已废弃X-前缀，但仍是常见约定）
            # 可能的值：
            # - MISS: 未命中缓存，直接从后端获取
            # - HIT: 命中缓存，直接返回缓存内容
            # - EXPIRED: 缓存已过期，重新向后端请求
            # - REVALIDATED: 缓存已过期，但重新验证后仍然有效
            # - UPDATING: 缓存正在更新，返回旧内容
            # - STALE: 缓存已过期，但仍然返回旧内容
			add_header X-Cache-Status $upstream_cache_status;

			proxy_pass http://backendserver;
		}

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/local/openresty/nginx/html;
        }
    }
}
