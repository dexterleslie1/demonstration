# nginx.conf  --  docker-openresty
#
# This file is installed to:
#   `/usr/local/openresty/nginx/conf/nginx.conf`
# and is the file loaded by nginx at startup,
# unless the user specifies otherwise.
#
# It tracks the upstream OpenResty's `nginx.conf`, but removes the `server`
# section and adds this directive:
#     `include /etc/nginx/conf.d/*.conf;`
#
# The `docker-openresty` file `nginx.vh.default.conf` is copied to
# `/etc/nginx/conf.d/default.conf`.  It contains the `server section
# of the upstream `nginx.conf`.
#
# See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files
#

#user  nobody;
#worker_processes 1;

# Enables the use of JIT for regular expressions to speed-up their processing.
pcre_jit on;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# 开启debug级别日志，否则ngx.log不能输出debug级别日志
# https://stackoverflow.com/questions/55975325/nothing-is-written-to-nginx-access-log-error-log-how-to-troubleshoot
error_log  logs/error.log  notice;

#pid        logs/nginx.pid;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    # Enables or disables the use of underscores in client request header fields.
    # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive.
    # underscores_in_headers off;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;
    access_log off;

        # Log in JSON Format
        # log_format nginxlog_json escape=json '{ "timestamp": "$time_iso8601", '
        # '"remote_addr": "$remote_addr", '
        #  '"body_bytes_sent": $body_bytes_sent, '
        #  '"request_time": $request_time, '
        #  '"response_status": $status, '
        #  '"request": "$request", '
        #  '"request_method": "$request_method", '
        #  '"host": "$host",'
        #  '"upstream_addr": "$upstream_addr",'
        #  '"http_x_forwarded_for": "$http_x_forwarded_for",'
        #  '"http_referrer": "$http_referer", '
        #  '"http_user_agent": "$http_user_agent", '
        #  '"http_version": "$server_protocol", '
        #  '"nginx_access": true }';
        # access_log /dev/stdout nginxlog_json;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    # 演示使用resty.limit.traffic模块组合限制
    # https://github.com/openresty/lua-resty-limit-traffic/blob/master/lib/resty/limit/traffic.md
    lua_shared_dict my_req_store 100m;
    lua_shared_dict my_conn_store 100m;

    init_by_lua_block {
        -- 是否面向客户端的openresty
        -- 是：防止客户端伪造x-forwarded-for头
        -- 否：不需要任何处理
        frontend = false
        rate = 5
        burst = 0
        conn = 2
        connBurst = 4
        xCount = 10
        xTimeWindow = 5;

        -- 获取客户端ip地址
        function get_client_ip(frontend --[[是否面向客户端的openresty]])
            local client_ip = nil
            if frontend then
                client_ip = ngx.var.remote_addr
            else
                -- 非面向客户端的openresty，解析x-forwarded-for中第一个ip地址作为客户端ip地址
                local headers = ngx.req.get_headers()
                local xForwardedFor = headers["x-forwarded-for"]
                if xForwardedFor then
                    for field in xForwardedFor:gmatch('([^,]+)') do
                        client_ip = field
                        break
                    end
                else
                    -- 如果没有x-forwarded-for（这是意料之外，不应该发生）
                    client_ip = ngx.var.remote_addr
                end
            end

            return client_ip
        end

        math.randomseed(ngx.now())

        local limit_conn = require "resty.limit.conn"
        local limit_req = require "resty.limit.req"
        limit_traffic = require "resty.limit.traffic"

        -- lim1, err = limit_req.new("my_req_store", 300, 200)
        -- assert(lim1, err)
        lim2, err = limit_req.new("my_req_store", rate, burst)
        assert(lim2, err)
        lim3, err = limit_conn.new("my_conn_store", conn, connBurst, 0.5)
        assert(lim3, err)

        -- limiters = {lim1, lim2, lim3}
        limiters = {lim2, lim3}
    }

    access_by_lua_block {
        -- 如果是面向客户端的openresty防止客户端伪造x-forwarded-for头
        if frontend then
            -- 删除客户端传来的x-forwarded-for头
            ngx.req.clear_header("x-forwarded-for");
            -- 设置客户端ip地址
            local client_ip = ngx.var.remote_addr
            ngx.req.set_header("x-forwarded-for", client_ip);
            -- ngx.log(ngx.NOTICE, "客户端ip地址：" .. client_ip)
        end

        -- local host = ngx.var.host
        local client = get_client_ip(frontend)
        -- local keys = {host, client, client}
        local keys = {client, client}

        local states = {}

        local delay, err = limit_traffic.combine(limiters, keys, states)
        if not delay then
            if err == "rejected" then
                return ngx.exit(503)
            end
            ngx.log(ngx.ERR, "failed to limit traffic: ", err)
            return ngx.exit(500)
        end

        if lim3:is_committed() then
            local ctx = ngx.ctx
            ctx.limit_conn = lim3
            ctx.limit_conn_key = keys[#keys]
        end

        if delay >= 0.001 then
            ngx.log(ngx.NOTICE, "sleeping ", delay, " sec, states: ", table.concat(states, ", "))

            -- 如果lim2触发
            --[[if states[1] > 0 then
                ngx.log(ngx.NOTICE, "lim2触发")
            elseif states[2] > conn then
                ngx.log(ngx.NOTICE, "lim3触发")
            else
                ngx.log(ngx.WARN, "无法判断哪个规则触发，状态：" .. table.concat(states, ", "))
            end]]

            ngx.sleep(delay)
        end
    }

    # content handler goes here. if it is content_by_lua, then you can
    # merge the Lua code above in access_by_lua into your
    # content_by_lua's Lua handler to save a little bit of CPU time.

    log_by_lua_block {
        local ctx = ngx.ctx
        local lim = ctx.limit_conn
        if lim then
            -- if you are using an upstream module in the content phase,
            -- then you probably want to use $upstream_response_time
            -- instead of $request_time below.
            local latency = tonumber(ngx.var.request_time)
            local key = ctx.limit_conn_key
            assert(key)
            local conn, err = lim:leaving(key, latency)
            if not conn then
                ngx.log(ngx.ERR,
                        "failed to record the connection leaving ",
                        "request: ", err)
                return
            end
        end
    }

    server {
    	listen       80;
    	server_name  localhost;
	
    	location / {
       		#root   /usr/local/openresty/nginx/html;
        	#index  index.html index.htm;
            content_by_lua_block {
                ngx.header.content_type = "text/plain;charset=utf-8";
                ngx.sleep(1)
                ngx.say("Hello Dexterleslie！当前时间：" .. ngx.now());
            }
    	}
    }
}
