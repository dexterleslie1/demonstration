version: "3.8"

services:
#  service:
#    build:
#      context: ./service
#      dockerfile: Dockerfile
#    image: registry.cn-hangzhou.aliyuncs.com/future-public/demo-kafka-benchmark-service
#    environment:
#      - JAVA_OPTS=-Xmx1g
#      - TZ=Asia/Shanghai
#      - kafka_bootstrap_servers=kafka
#    ports:
#      - '8080:8080'
#  crond:
#    build:
#      context: ./crond
#      dockerfile: Dockerfile
#    image: registry.cn-hangzhou.aliyuncs.com/future-public/demo-kafka-benchmark-crond
#    environment:
#      - JAVA_OPTS=-Xmx1g
#      - TZ=Asia/Shanghai
#      - kafka_bootstrap_servers=kafka

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      TZ: Asia/Shanghai
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # todo 设置 ZooKeeper 的 JVM 堆内存
      # ZOOKEEPER_HEAP_OPTS: "-Xms1g -Xmx1g"
    ports:
      - "2181:2181"
  kafka1:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      # 映射 JMX 端口到主机
      # - "9997:9997"
    environment:
      TZ: Asia/Shanghai
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${kafka_advertised_listeners}:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # 设置 Kafka 的 JVM 堆内存
      KAFKA_HEAP_OPTS: "-Xms1g -Xmx1g"
      # 配置 JMX 端口和认证，配置了 jmx 端口才能够被外部工具监控
      # KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=9997 -Dcom.sun.management.jmxremote.rmi.port=9997"
      # 禁用自动创建 Topic，否则 Spring Boot 会自动创建 partitions=0 的 topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      # ------------------- 日志清理配置 -------------------
      # 清理策略：启用 delete（按时间/大小删除）
      KAFKA_LOG_CLEANUP_POLICY: "delete"
      # 单个分区最大日志大小：2G（根据磁盘容量调整，如 5GB、20GB）
      KAFKA_LOG_RETENTION_BYTES: "2147483648"  # 设为 -1 表示不限制大小（仅用时间策略）
      # 日志段大小：512MB（更小的段可提升清理精度，但增加文件数）
      KAFKA_LOG_SEGMENT_BYTES: "536870912"  #（原默认 1GB）
#      # 单个分区最大日志大小：1MB（根据磁盘容量调整，如 5GB、20GB）
#      KAFKA_LOG_RETENTION_BYTES: "1048576"  # 设为 -1 表示不限制大小（仅用时间策略）
#      # 日志段大小：256KB（更小的段可提升清理精度，但增加文件数）
#      KAFKA_LOG_SEGMENT_BYTES: "262144"  #（原默认 1GB）
#  kafka2:
#    image: confluentinc/cp-kafka:7.3.0
#    depends_on:
#      - zookeeper
#    ports:
#      - "9093:9093"
#      # 映射 JMX 端口到主机
#      # - "9997:9997"
#    environment:
#      TZ: Asia/Shanghai
#      KAFKA_BROKER_ID: 2
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${kafka_advertised_listeners}:9093
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#      # 设置 Kafka 的 JVM 堆内存
#      KAFKA_HEAP_OPTS: "-Xms1g -Xmx1g"
#      # 配置 JMX 端口和认证，配置了 jmx 端口才能够被外部工具监控
#      # KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=9997 -Dcom.sun.management.jmxremote.rmi.port=9997"
#      # 禁用自动创建 Topic，否则 Spring Boot 会自动创建 partitions=0 的 topic
#      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
#      # ------------------- 日志清理配置 -------------------
#      # 清理策略：启用 delete（按时间/大小删除）
#      KAFKA_LOG_CLEANUP_POLICY: "delete"
#      # 单个分区最大日志大小：2G（根据磁盘容量调整，如 5GB、20GB）
#      KAFKA_LOG_RETENTION_BYTES: "2147483648"  # 设为 -1 表示不限制大小（仅用时间策略）
#      # 日志段大小：512MB（更小的段可提升清理精度，但增加文件数）
#      KAFKA_LOG_SEGMENT_BYTES: "536870912"  #（原默认 1GB）
#  #      # 单个分区最大日志大小：1MB（根据磁盘容量调整，如 5GB、20GB）
#  #      KAFKA_LOG_RETENTION_BYTES: "1048576"  # 设为 -1 表示不限制大小（仅用时间策略）
#  #      # 日志段大小：256KB（更小的段可提升清理精度，但增加文件数）
#  #      KAFKA_LOG_SEGMENT_BYTES: "262144"  #（原默认 1GB）

  # 在 kafka 服务成功启动后自动配置 kafka 服务
  kafka-create-topic1:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka1
    environment:
      TZ: Asia/Shanghai
    # 自动创建 topic
    entrypoint: /usr/bin/kafka-topics --create --bootstrap-server kafka1:9092 --replication-factor 1 --partitions 256 --topic my-topic-1
  kafka-create-topic2:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka1
    environment:
      TZ: Asia/Shanghai
    # 自动创建 topic
    entrypoint: /usr/bin/kafka-topics --create --bootstrap-server kafka1:9092 --replication-factor 1 --partitions 2 --topic my-topic-2
  kafka-create-topic-test-send-perf:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka1
    environment:
      TZ: Asia/Shanghai
    # 自动创建 topic
    entrypoint: /usr/bin/kafka-topics --create --bootstrap-server kafka1:9092 --replication-factor 1 --partitions 1 --topic topic-test-send-perf
  kafka-create-topic-test-alter-partitions-online:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka1
    environment:
      TZ: Asia/Shanghai
    entrypoint: /usr/bin/kafka-topics --create --bootstrap-server kafka1:9092 --replication-factor 1 --partitions 1 --topic topic-test-alter-partitions-online
  kafka-manager:
    image: sheepkiller/kafka-manager:latest
    ports:
      - "9000:9000"
    environment:
      TZ: Asia/Shanghai
      ZK_HOSTS: zookeeper:2181
      APPLICATION_SECRET: "123456"

  redis:
    image: redis:7.2.4
    # 设置redis密码
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass 123456
    volumes:
      - ./deployer/common/redis7.conf:/usr/local/etc/redis/redis.conf
    environment:
      - TZ=Asia/Shanghai
    network_mode: host
