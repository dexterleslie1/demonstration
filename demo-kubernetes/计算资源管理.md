

# 计算资源管理

> 注意：停止其他工作节点只保留一个并且配置调整为2核

## 为`pod`中的容器申请资源

> 注意：设置`pod`的容器资源申请量保证了每个容器能够获得他所需要的资源的最小量。

### 创建包含资源`requests`的`pod`

```shell
# 用于创建测试pod
apiVersion: v1
kind: Pod
metadata:
 name: test
spec:
 containers:
 - name: main
   image: busybox
   command: ["dd", "if=/dev/zero", "of=/dev/null"]
   # 我们为主容器指定了资源请求量
   # 容器申请200毫核（即一个cpu核心时间的1/5）
   # 容器申请10MB内存
   resources:
    requests:
     cpu: 200m
     memory: 10Mi
     
     
# 我们在容器中执行dd命令会消耗尽可能多的cpu，但因为他是单线程运行所以最多之能跑满一个核，而宿主节点有2个cpu，所以这里top命令显示cpu使用率为50%
# 对于2核来说，50%显然就是指一个核，说明容器实际使用量超过了我们pod定义中申请的200毫核。这是符合预期的，因为requests不会限制容器可以使用的cpu数量。我们需要指定cpu限制来实现这一点，稍后会进行尝试
kubectl exec -it test sh
# 在容器中查看cpu使用率
/ # top
```



### 资源`requests`如何影响调度

```shell
# 查看节点的资源总量（Capacity）和可分配的资源剩余量（Allocatable）
kubectl get node
kubectl describe node demo-k8s-node0

# 创建一个请求量cpu=800m的pod
kubectl run test1 --image=busybox --restart=Never --requests='cpu=800m,memory=20Mi' -- dd if=/dev/zero of=/dev/null

# 再创建一个请求量cpu=1的pod
# 因为我们之前申请了200m+800m=1000m的pod，加上kube-system命名空间中申请的cpu量已经超过1000m，导致剩余的cpu不足当前申请的cpu=1（1000m），所以pod一直处于Pending状态。
kubectl run test2 --image=busybox --restart=Never --requests='cpu=1,memory=20Mi' -- dd if=/dev/zero of=/dev/null
# 通过命令查看test2 pod部署失败的原因
kubectl describe pod test2

# 删除test1 pod让test2 pod调度成功
kubectl delete pod test1

# 查看test2 pod调度成功
kubectl get pod -o wide
```



### `cpu requests`如何影响`cpu`时间分配

`cpu requests`不仅仅在调度时起作用，他还决定着剩余（未使用）的`cpu`时间如何在`pod`之间分配。因为第一个`pod`请求了200毫核，另外一个请求了1000毫核，所以未使用的`cpu`将按照1:5的比例来划分给这两个`pod`。如果两个`pod`都全力使用`cpu`，第一个`pod`将获得16.7%的`cpu`时间，另一个将获得83.3%的`cpu`时间。
另一方面，如果一个容器能够跑满`cpu`，而另一个容器在该时段处于空闲状态，那么前者将可以使用这个cpu时间（当然会减掉第二个容器消耗的少量时间）。毕竟没有其他人使用时提高整个`cpu`的利用率也是有意义的，对吧？当然，第二个容器需要`cpu`时间的时候就会获取到，同时第一个容器会被限制回来。



## 限制容器的可用资源

与资源requests不同的是，资源limits不受节点可分配资源量的约束。所有limits的总和允许超过资源总量的100%。换句话说，资源limits可以超卖。如果节点资源使用量超过100%，一些容器将被杀掉，这是一个很重要的结果。
对一进程的CPU使用率可以进行限制，因此当一个容器设置CPU限额时，该进程只会分不到比限额更多的CPU而已。
而内存却有所不同。当进程尝试申请分配比限额更多的内存时会被杀掉（我们会说这个容器被OOMKilled了，OOM是Out Of Memory缩写）。如果pod的重启策略为Always或者OnFailure，进程将会立即重启，因此用户可能根本觉察不到他被杀掉。但是如果他继续超限并被杀死，kubernetes会再次尝试重启，并且增加下次重启的间隔时间。

### 创建一个带有资源`limits`的`pod`

```shell
apiVersion: v1
kind: Pod
metadata:
 name: test
spec:
 containers:
 - name: main
   image: busybox
   command: ["dd", "if=/dev/zero", "of=/dev/null"]
   resources:
    # 我们为容器指定资源limits
    # 这个容器允许最大使用1/5核cpu
    # 这个容器允许最大使用20MB内存
    # 因为没有指定资源requests，他将被设置为与资源limits相同的值
    limits:
     cpu: 200m
     memory: 20Mi
    
# 可以看到cpu使用率为10%，因为宿主节点是2核cpu，所以200m=10%cpu使用率
kubectl exec -it test sh
/ # top
```

 

### 容器中的应用如何看待`limits`

在容器内看到的始终是节点的内存，而不是容器本身的内存。即使你为容器设置了最大可用内存限制，top命令显示的是运行该容器的节点的内存数量，而容器无法感知到此限制。
容器内同样可以看到节点所有的cpu核，与内存一样，无论有没有配置CPU limits，容器内也会看到节点所有的CPU。将CPU限额配置为1,并不会神奇地只为容器暴露一个核。CPU limits做的只是限制容器使用CPU时间。
一些程序通过查询系统CPU核数来决定启动工作线程的数量。同样在开发环境的笔记本电脑上运行良好，但是部署在拥有更多数量的CPU节点上，程序将快速启动大量线程，所有线程都会争夺（可能极其）有限的CPU时间。同时每个线程通常都需要额外的内存资源，导致应用的内存用量急剧增加。
不要依赖应用程序从系统获取CPU数量，你可能需要使用Downward API将CPU限额传递至容器并使用这个值。也可以通过cgroup系统直接获取配置的CPU限制。请查看下面的文件: /sys/fs/cgroup/cpu/cpu.cfs.quota.us、/sys/fs/cgroup/cpu/cpu.cfs_period_us



## 了解`pod QoS`等级

假设有两个pod，pod A使用了节点内存的90%，pod B突然需要比之前更多的内存，这时节点无法提供足量的内存，哪个容器将被杀掉呢？应该是pod B吗？因为节点无法满足他的内存要求。或者应该是pod A吗？这样释放的内存就可以提供给pod B了。









